{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, ConfusionMatrixDisplay\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1080'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Anam Destresse, président de l'ONG \"Ma passion...</td>\n",
       "      <td>[{'id': 0, 'mentions': [{'value': 'accident', ...</td>\n",
       "      <td>[[0, STARTED_IN, 9], [7, IS_LOCATED_IN, 9], [5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31669</th>\n",
       "      <td>À Paris, le 8 avril 2022, l'usine de déodorant...</td>\n",
       "      <td>[{'id': 0, 'mentions': [{'value': 'explosé', '...</td>\n",
       "      <td>[[9, IS_LOCATED_IN, 8], [11, OPERATES_IN, 8], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51470</th>\n",
       "      <td>En Espagne, dans une région agricole, une cont...</td>\n",
       "      <td>[{'id': 0, 'mentions': [{'value': 'contaminati...</td>\n",
       "      <td>[[7, IS_PART_OF, 8], [9, OPERATES_IN, 1], [0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51332</th>\n",
       "      <td>Un important incendie a fait des ravages dans ...</td>\n",
       "      <td>[{'id': 0, 'mentions': [{'value': 'incendie', ...</td>\n",
       "      <td>[[12, IS_IN_CONTACT_WITH, 5], [0, IS_LOCATED_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>« Je coule » : onze heures après avoir envoyé ...</td>\n",
       "      <td>[{'id': 0, 'mentions': [{'value': 'renversé', ...</td>\n",
       "      <td>[[9, IS_LOCATED_IN, 2], [0, START_DATE, 17], [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "id                                                         \n",
       "181    Anam Destresse, président de l'ONG \"Ma passion...   \n",
       "31669  À Paris, le 8 avril 2022, l'usine de déodorant...   \n",
       "51470  En Espagne, dans une région agricole, une cont...   \n",
       "51332  Un important incendie a fait des ravages dans ...   \n",
       "1131   « Je coule » : onze heures après avoir envoyé ...   \n",
       "\n",
       "                                                entities  \\\n",
       "id                                                         \n",
       "181    [{'id': 0, 'mentions': [{'value': 'accident', ...   \n",
       "31669  [{'id': 0, 'mentions': [{'value': 'explosé', '...   \n",
       "51470  [{'id': 0, 'mentions': [{'value': 'contaminati...   \n",
       "51332  [{'id': 0, 'mentions': [{'value': 'incendie', ...   \n",
       "1131   [{'id': 0, 'mentions': [{'value': 'renversé', ...   \n",
       "\n",
       "                                               relations  \n",
       "id                                                        \n",
       "181    [[0, STARTED_IN, 9], [7, IS_LOCATED_IN, 9], [5...  \n",
       "31669  [[9, IS_LOCATED_IN, 8], [11, OPERATES_IN, 8], ...  \n",
       "51470  [[7, IS_PART_OF, 8], [9, OPERATES_IN, 1], [0, ...  \n",
       "51332  [[12, IS_IN_CONTACT_WITH, 5], [0, IS_LOCATED_I...  \n",
       "1131   [[9, IS_LOCATED_IN, 2], [0, START_DATE, 17], [...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "train_df = train_df.set_index(\"id\")\n",
    "train_df.entities = train_df.entities.apply(json.loads)  # Parse entities\n",
    "train_df.relations = train_df.relations.apply(json.loads)  # Parse relations\n",
    "\n",
    "# Display the first few rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 Relation types: ['START_DATE', 'END_DATE', 'IS_OF_NATIONALITY', 'INITIATED', 'IS_LOCATED_IN', 'HAS_FOR_LENGTH', 'IS_REGISTERED_AS', 'HAS_CONSEQUENCE', 'WEIGHS', 'INJURED_NUMBER', 'GENDER_FEMALE', 'HAS_FOR_WIDTH', 'HAS_CONTROL_OVER', 'HAS_LONGITUDE', 'IS_OF_SIZE', 'IS_COOPERATING_WITH', 'HAS_CATEGORY', 'HAS_FAMILY_RELATIONSHIP', 'HAS_LATITUDE', 'HAS_COLOR', 'IS_IN_CONTACT_WITH', 'GENDER_MALE', 'DEATHS_NUMBER', 'OPERATES_IN', 'HAS_QUANTITY', 'IS_PART_OF', 'CREATED', 'WAS_DISSOLVED_IN', 'RESIDES_IN', 'WAS_CREATED_IN', 'IS_AT_ODDS_WITH', 'IS_BORN_ON', 'HAS_FOR_HEIGHT', 'IS_DEAD_ON', 'STARTED_IN', 'IS_BORN_IN', 'DIED_IN']\n"
     ]
    }
   ],
   "source": [
    "# Extract all unique relation types\n",
    "relation_types = set()\n",
    "for relations in train_df.relations:\n",
    "    for rel in relations:\n",
    "        relation_types.add(rel[1])  # rel[1] is the relation type\n",
    "relation_types = list(relation_types)\n",
    "print(len(relation_types), \"Relation types:\", relation_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONTOLOGY_RELATIONS = [\n",
    "    \"HAS_CONTROL_OVER\",\n",
    "    \"STARTED_IN\",\n",
    "    \"IS_LOCATED_IN\",\n",
    "    \"HAS_CATEGORY\",\n",
    "    \"IS_PART_OF\",\n",
    "    \"INJURED_NUMBER\",\n",
    "    \"IS_OF_NATIONALITY\",\n",
    "    \"OPERATES_IN\",\n",
    "    \"INITIATED\",\n",
    "    \"RESIDES_IN\",\n",
    "    \"HAS_CONSEQUENCE\",\n",
    "    \"IS_COOPERATING_WITH\",\n",
    "    \"IS_IN_CONTACT_WITH\",\n",
    "    \"IS_OF_SIZE\",\n",
    "    \"HAS_QUANTITY\",\n",
    "    \"HAS_FOR_LENGTH\",\n",
    "    \"IS_BORN_IN\",\n",
    "    \"WEIGHS\",\n",
    "    \"HAS_FOR_WIDTH\",\n",
    "    \"HAS_COLOR\",\n",
    "    \"HAS_LATITUDE\",\n",
    "    \"IS_REGISTERED_AS\",\n",
    "    \"IS_AT_ODDS_WITH\",\n",
    "    \"CREATED\",\n",
    "    \"HAS_FAMILY_RELATIONSHIP\",\n",
    "    \"DEATHS_NUMBER\",\n",
    "    \"HAS_FOR_HEIGHT\",\n",
    "    \"HAS_LONGITUDE\",\n",
    "    \"IS_DEAD_ON\",\n",
    "    \"START_DATE\",\n",
    "    \"END_DATE\",\n",
    "    \"WAS_CREATED_IN\",\n",
    "    \"IS_BORN_ON\",\n",
    "    \"WAS_DISSOLVED_IN\",\n",
    "    \"DIED_IN\",\n",
    "    \"GENDER_FEMALE\",\n",
    "    \"GENDER_MALE\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "print(len(ONTOLOGY_RELATIONS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to mark entities in the text\n",
    "def mark_entities(text, entities):\n",
    "    marked_text = text\n",
    "    for entity in entities:\n",
    "        mention = entity[\"mentions\"][0]\n",
    "        value, start, end = mention[\"value\"], mention[\"start\"], mention[\"end\"]\n",
    "        marked_text = f\"{marked_text[:start]}[E{entity['id']}]{value}[/E{entity['id']}]{marked_text[end:]}\"\n",
    "    return marked_text\n",
    "\n",
    "# Prepare the dataset\n",
    "def prepare_dataset(df, relation_types):\n",
    "    data = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = row[\"text\"]\n",
    "        entities = row[\"entities\"]\n",
    "        relations = row[\"relations\"]\n",
    "        marked_text = mark_entities(text, entities)\n",
    "        for rel in relations:\n",
    "            e1_id, rel_type, e2_id = rel\n",
    "            data.append({\"text\": marked_text, \"label\": relation_types.index(rel_type)})\n",
    "    return data\n",
    "\n",
    "# Split the dataset\n",
    "dataset = prepare_dataset(train_df, relation_types)\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CamemBERT tokenizer\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Custom Dataset Class\n",
    "class RelationDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            item[\"text\"],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"],\n",
    "            \"attention_mask\": encoding[\"attention_mask\"],\n",
    "            \"labels\": item[\"label\"],\n",
    "        }\n",
    "\n",
    "train_dataset = RelationDataset(train_data, tokenizer)\n",
    "val_dataset = RelationDataset(val_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator for dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load CamemBERT with a classification head\n",
    "model = CamembertForSequenceClassification.from_pretrained(\n",
    "    \"camembert-base\",\n",
    "    num_labels=len(relation_types)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Overall metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    \n",
    "    # Per-class metrics\n",
    "    class_report = classification_report(labels, predictions, target_names=relation_types, output_dict=True, zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_weighted': f1,\n",
    "        'precision_weighted': precision,\n",
    "        'recall_weighted': recall,\n",
    "        **{f'f1_{cls}': class_report[cls]['f1-score'] for cls in relation_types},  # Per-class F1\n",
    "        **{f'precision_{cls}': class_report[cls]['precision'] for cls in relation_types},  # Per-class precision\n",
    "        **{f'recall_{cls}': class_report[cls]['recall'] for cls in relation_types},  # Per-class recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Trainer with data collator\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset, # Automatically shuffled\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='159' max='4722' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 159/4722 26:44 < 12:57:21, 0.10 it/s, Epoch 0.10/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thebo\\Desktop\\TextMine25\\env_textmine\\Lib\\site-packages\\transformers\\trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thebo\\Desktop\\TextMine25\\env_textmine\\Lib\\site-packages\\transformers\\trainer.py:2531\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2524\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2525\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2528\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2529\u001b[0m )\n\u001b[0;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2537\u001b[0m ):\n\u001b[0;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\thebo\\Desktop\\TextMine25\\env_textmine\\Lib\\site-packages\\transformers\\trainer.py:3712\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_accepts_loss_kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3710\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[1;32m-> 3712\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3714\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32mc:\\Users\\thebo\\Desktop\\TextMine25\\env_textmine\\Lib\\site-packages\\accelerate\\accelerator.py:2246\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2246\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thebo\\Desktop\\TextMine25\\env_textmine\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thebo\\Desktop\\TextMine25\\env_textmine\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thebo\\Desktop\\TextMine25\\env_textmine\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_class(model, dataloader, relation_types, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    predictions, labels = [], []\n",
    "\n",
    "    # Process the dataset in batches\n",
    "    for batch in dataloader:\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device),\n",
    "            'labels': batch['labels'].to(device)\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions.extend(torch.argmax(logits, dim=-1).cpu().numpy())\n",
    "        labels.extend(inputs['labels'].cpu().numpy())\n",
    "\n",
    "    # Compute per-class metrics\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        labels, predictions, labels=list(range(len(relation_types))), average=None, zero_division=0\n",
    "    )\n",
    "\n",
    "    # Create a DataFrame for better readability\n",
    "    report_df = pd.DataFrame({\n",
    "        'Class': relation_types,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Support': support\n",
    "    })\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    cm = confusion_matrix(labels, predictions, labels=list(range(len(relation_types))))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=relation_types)\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation=90)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    return report_df\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "# Evaluate per-class performance on the validation set\n",
    "report_df = evaluate_per_class(model, val_loader, relation_types)\n",
    "\n",
    "# Print the report\n",
    "print(\"Per-Class Performance Report:\")\n",
    "print(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"../camembert-relation-extraction\")\n",
    "tokenizer.save_pretrained(\"../camembert-relation-extraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = CamembertForSequenceClassification.from_pretrained(\"../camembert-relation-extraction\")\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"../camembert-relation-extraction\")\n",
    "\n",
    "# Example prediction\n",
    "test_text = \"[E1]Anam Destresse[/E1] a été blessé dans un accident impliquant un [E2]bus[/E2].\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "outputs = model(**inputs)\n",
    "predicted_label = outputs.logits.argmax(dim=-1).item()\n",
    "predicted_relation = relation_types[predicted_label]\n",
    "\n",
    "print(f\"Predicted relation: {predicted_relation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Weights:\n",
    "Use class weights in the loss function to penalize misclassifications in minority classes more heavily.\n",
    "\n",
    "Oversampling/Downsampling:\n",
    "Oversample minority classes or downsample majority classes during training.\n",
    "\n",
    "Data Augmentation:\n",
    "Augment data for minority classes to balance the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_textmine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
